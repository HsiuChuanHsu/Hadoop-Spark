
version: "3"
services:
    namenode:
        image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
        container_name: namenode
        restart: always
        volumes:
            - hadoop_namenode:/hadoop/dfs/name
        environment:
            - CLUSTER_NAME=test
        ports:
            - 9870:9870
            - 9000:9000
        env_file:
            - ./hadoop.env
        networks:
            - hadoop

    datanode:
        image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
        container_name: datanode
        restart: always
        depends_on: 
            - namenode
        volumes:
            - hadoop_datanode:/hadoop/dfs/data
        environment:
            SERVICE_PRECONDITION: "namenode:9870"
        ports:
            - 9864:9864
        env_file:
            - ./hadoop.env
        networks:
            - hadoop

    resourcemanager:
        image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
        container_name: resourcemanager
        restart: always
        environment:
            SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
        ports:
            - 8088:8088
        env_file:
            - ./hadoop.env
        networks:
            - hadoop
    
    nodemanager:
        image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
        container_name: nodemanager
        restart: always
        environment:
            SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
        ports:
            - 8042:8042
        env_file:
            - ./hadoop.env
        networks:
            - hadoop
    
    historyserver:
        image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
        container_name: historyserver
        restart: always
        environment:
            SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
        volumes:
            - hadoop_historyserver:/hadoop/yarn/timeline
        ports:
            - 8188:8188
        env_file:
            - ./hadoop.env
        networks:
            - hadoop

      
    spark-master:
        # platform: linux/amd64/v8
        image: bde2020/spark-master:3.0.2-hadoop3.2
        container_name: spark-master
        depends_on:
            - namenode
            - datanode
        environment:
            - INIT_DAEMON_STEP=setup_spark
        ports:
            - 8080:8080
            - 7077:7077
            - 4040:4040
            - 18080:18080
        env_file:
            - ./hadoop.env
        networks:
            - hadoop


    jupyter:
        image: jupyter/pyspark-notebook:latest
        container_name: jupyter
        ports:
            - 8888:8888
        volumes:
            - ./notebooks:/home/jovyan/work  # Mount a local directory to store notebooks
            - ./JDBC_Driver:/Drivers/SQL_Sever/jdbc

        environment:
            - SPARK_MASTER=spark://spark-master:7077  # Point to your Spark master
        networks:
            - hadoop

    zookeeper:
        image: confluentinc/cp-zookeeper:7.4.0
        hostname: zookeeper
        container_name: zookeeper
        ports:
            - "2181:2181"
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
        healthcheck:
            test: ['CMD', 'bash', '-c', "echo 'ruok' | nc localhost 2181"]
            interval: 10s
            timeout: 5s
            retries: 5
        networks:
            - hadoop

    broker:
        image: confluentinc/cp-server:7.4.0
        hostname: broker
        container_name: broker
        depends_on:
            zookeeper:
                condition: service_healthy
        ports:
            - "9092:9092"
            - "29092:29092"
            - "9101:9101"
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
            KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_JMX_PORT: 9101
            KAFKA_JMX_HOSTNAME: localhost
            KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
            CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
            CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
            CONFLUENT_METRICS_ENABLE: 'false'
            CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
        networks:
            - hadoop
        healthcheck:
            test: [ "CMD", "bash", "-c", 'nc -z localhost 9092' ]
            interval: 10s
            timeout: 5s
            retries: 5

    schema-registry:
        image: confluentinc/cp-schema-registry:7.4.0
        hostname: schema-registry
        container_name: schema-registry
        depends_on:
            broker:
                condition: service_healthy
        ports:
            - "8081:8081"
        environment:
            SCHEMA_REGISTRY_HOST_NAME: schema-registry
            SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
            SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
        networks:
            - hadoop
        healthcheck:
            test: [ "CMD", "curl", "-f", "http://localhost:8081/" ]
            interval: 30s
            timeout: 10s
            retries: 5

    control-center:
        image: confluentinc/cp-enterprise-control-center:7.4.0
        hostname: control-center
        container_name: control-center
        depends_on:
            broker:
                condition: service_healthy
            schema-registry:
                condition: service_healthy
        ports:
            - "9021:9021"
        environment:
            CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
            CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
            CONTROL_CENTER_REPLICATION_FACTOR: 1
            CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
            CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
            CONFLUENT_METRICS_TOPIC_REPLICATION: 1
            CONFLIENT_METRICS_ENABLE: 'false'
            PORT: 9021
        networks:
            - hadoop
        healthcheck:
            test: [ "CMD", "curl", "-f", "http://localhost:9021/health" ]
            interval: 30s
            timeout: 10s
            retries: 5
volumes:
    hadoop_namenode:
    hadoop_datanode:
    hadoop_historyserver:
networks:
  hadoop:
      name: hadoop